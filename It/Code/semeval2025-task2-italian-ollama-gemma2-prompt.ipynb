{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":10748145,"datasetId":6347856,"databundleVersionId":11100777}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n    # for filename in filenames:\n    #     print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-14T09:18:50.768874Z","iopub.execute_input":"2025-02-14T09:18:50.769337Z","iopub.status.idle":"2025-02-14T09:18:50.773748Z","shell.execute_reply.started":"2025-02-14T09:18:50.769309Z","shell.execute_reply":"2025-02-14T09:18:50.772798Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip -q install --upgrade ollama","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T09:18:55.513841Z","iopub.execute_input":"2025-02-14T09:18:55.514131Z","iopub.status.idle":"2025-02-14T09:19:00.358829Z","shell.execute_reply.started":"2025-02-14T09:18:55.514109Z","shell.execute_reply":"2025-02-14T09:19:00.357877Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!curl -fsSL https://ollama.com/install.sh | sh","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T09:19:06.279927Z","iopub.execute_input":"2025-02-14T09:19:06.280245Z","iopub.status.idle":"2025-02-14T09:19:47.166079Z","shell.execute_reply.started":"2025-02-14T09:19:06.280218Z","shell.execute_reply":"2025-02-14T09:19:47.165222Z"}},"outputs":[{"name":"stdout","text":">>> Installing ollama to /usr/local\n>>> Downloading Linux amd64 bundle\n############################################################################################# 100.0%                                                                                  2.1%###############                                                                34.3%############                                                    46.9%##########################################################                    81.7%\n>>> Creating ollama user...\n>>> Adding ollama user to video group...\n>>> Adding current user to ollama group...\n>>> Creating ollama systemd service...\n\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n>>> The Ollama API is now available at 127.0.0.1:11434.\n>>> Install complete. Run \"ollama\" from the command line.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nget_ipython().system = os.system","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T09:20:11.931408Z","iopub.execute_input":"2025-02-14T09:20:11.931828Z","iopub.status.idle":"2025-02-14T09:20:11.936178Z","shell.execute_reply.started":"2025-02-14T09:20:11.931778Z","shell.execute_reply":"2025-02-14T09:20:11.935267Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"!ollama serve &","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T09:20:14.671808Z","iopub.execute_input":"2025-02-14T09:20:14.672085Z","iopub.status.idle":"2025-02-14T09:20:14.681456Z","shell.execute_reply.started":"2025-02-14T09:20:14.672064Z","shell.execute_reply":"2025-02-14T09:20:14.680321Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"!ollama pull gemma2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T09:20:17.057364Z","iopub.execute_input":"2025-02-14T09:20:17.057709Z","iopub.status.idle":"2025-02-14T09:20:54.378672Z","shell.execute_reply.started":"2025-02-14T09:20:17.057679Z","shell.execute_reply":"2025-02-14T09:20:54.377816Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"import json\nfrom tqdm import tqdm\nimport ollama\n\n# from langchain_community.chat_models import ChatOllama\n# from langchain.document_loaders import WikipediaLoader\n# # from langchain_community.llms import Ollama\n# from langchain_ollama import OllamaLLM\n# from langchain.chains import LLMChain\n# from langchain.prompts.chat import (ChatPromptTemplate,HumanMessagePromptTemplate,SystemMessagePromptTemplate)\n# from langchain import PromptTemplate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T09:20:54.379874Z","iopub.execute_input":"2025-02-14T09:20:54.380153Z","iopub.status.idle":"2025-02-14T09:20:55.280021Z","shell.execute_reply.started":"2025-02-14T09:20:54.380131Z","shell.execute_reply":"2025-02-14T09:20:55.279124Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Path to your input and output files\ninput_file = \"/kaggle/input/task-2-ea-mt-entity-aware-machine-translation/it_IT_after-650f0ecb66f3636a.jsonl\"\noutput_file = \"translated_data_en_it_gemma2-_after-650f0ecb66f3636av1.jsonl\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T09:20:55.281320Z","iopub.execute_input":"2025-02-14T09:20:55.281592Z","iopub.status.idle":"2025-02-14T09:20:55.285611Z","shell.execute_reply.started":"2025-02-14T09:20:55.281564Z","shell.execute_reply":"2025-02-14T09:20:55.284793Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def translate_text(obj):\n    prompt = f\"\"\"\n    Translate the following English text into Italian with more attention on accurately translating the given named entities. \n    Do not add extra text.\n    \n    Entity Types: {', '.join(obj['entity_types'])}\n    Text: \"{obj['source']}\"\n    \n    Output the result in JSON format:\n    {{\n        \"id\": \"{obj['id']}\",\n        \"predicted_text\": \"<translated_text>\"\n    }}\n    \"\"\"\n    \n    response = ollama.chat(\n        model=\"gemma2\",\n        messages=[{\"role\": \"system\", \"content\": \"You are a translation assistant.\"},\n                  {\"role\": \"user\", \"content\": prompt}],\n        stream=False\n    )\n    \n    # Extract generated text and parse JSON\n    try:\n        content = response.message.content.strip()\n        # print(response.message.content)\n        # Remove markdown code block (```json ... ```)\n        if content.startswith(\"```json\"):\n            content = content[7:-3].strip()  # Remove first 7 (````json\\n`) and last 3 characters (`\\n````)\n        \n        output_json = json.loads(content)\n        return output_json\n    except json.JSONDecodeError:\n        print(f\"Error parsing response for ID: {obj['id']}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T09:20:55.286690Z","iopub.execute_input":"2025-02-14T09:20:55.286983Z","iopub.status.idle":"2025-02-14T09:20:55.306294Z","shell.execute_reply.started":"2025-02-14T09:20:55.286956Z","shell.execute_reply":"2025-02-14T09:20:55.305572Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"with open(input_file, \"r\", encoding=\"utf-8\") as f:\n    total_lines = sum(1 for _ in f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T09:20:56.334919Z","iopub.execute_input":"2025-02-14T09:20:56.335212Z","iopub.status.idle":"2025-02-14T09:20:56.348289Z","shell.execute_reply.started":"2025-02-14T09:20:56.335190Z","shell.execute_reply":"2025-02-14T09:20:56.347479Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n     with tqdm(total=total_lines, desc=\"Generating Predictions\", colour=\"blue\") as pbar:\n        for line in infile:\n            obj = json.loads(line.strip())\n            translated_obj = translate_text(obj)\n            # print(translated_obj)\n            # break\n            if translated_obj and (\"predicted_text\" in translated_obj):\n                translated_obj = {\n                    \"id\": obj[\"id\"],\n                    \"source_language\": \"English\",\n                    \"target_language\": \"Italian\", \n                    \"text\": obj[\"source\"],\n                    \"prediction\": translated_obj[\"predicted_text\"]\n                }\n                outfile.write(json.dumps(translated_obj, ensure_ascii=False) + \"\\n\")\n            pbar.update(1)\n\nprint(f\"Translation completed! Output saved to {output_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T09:20:58.085638Z","iopub.execute_input":"2025-02-14T09:20:58.085954Z"}},"outputs":[{"name":"stderr","text":"Generating Predictions:   1%|\u001b[34m          \u001b[0m| 16/1316 [00:35<44:02,  2.03s/it] ","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 2fa27215c342e0ae\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:   2%|\u001b[34m▏         \u001b[0m| 31/1316 [01:04<46:17,  2.16s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: a6abc435da8e1ad8\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:   3%|\u001b[34m▎         \u001b[0m| 40/1316 [01:24<46:58,  2.21s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: d7d15cef7eae1ad7\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:   4%|\u001b[34m▍         \u001b[0m| 54/1316 [01:55<48:29,  2.31s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: c4443e9ab86ab48a\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:   4%|\u001b[34m▍         \u001b[0m| 57/1316 [02:05<1:07:43,  3.23s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 3a48527962f594ef\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:   5%|\u001b[34m▍         \u001b[0m| 64/1316 [02:21<49:40,  2.38s/it]  ","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: a1ab8faedf46fe8b\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:   5%|\u001b[34m▍         \u001b[0m| 65/1316 [02:24<51:43,  2.48s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: b8d3752e872303dd\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:   6%|\u001b[34m▌         \u001b[0m| 75/1316 [02:46<49:48,  2.41s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 514963594930b40c\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:   6%|\u001b[34m▋         \u001b[0m| 84/1316 [03:05<47:09,  2.30s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 3c7f8b6075880ae4\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:   7%|\u001b[34m▋         \u001b[0m| 95/1316 [03:30<47:39,  2.34s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: ec0e1e1055311e5a\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:   8%|\u001b[34m▊         \u001b[0m| 102/1316 [03:46<49:21,  2.44s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: f03deccb12d8f3de\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:   8%|\u001b[34m▊         \u001b[0m| 103/1316 [03:48<47:31,  2.35s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: f1fe8ffeed86fe41\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:   8%|\u001b[34m▊         \u001b[0m| 104/1316 [03:51<49:54,  2.47s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 8939a64a4c60ff79\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:   8%|\u001b[34m▊         \u001b[0m| 109/1316 [04:03<51:29,  2.56s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 5227906a848b7785\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  10%|\u001b[34m█         \u001b[0m| 138/1316 [05:07<46:39,  2.38s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 701c68d74ed08f57\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  11%|\u001b[34m█         \u001b[0m| 140/1316 [05:15<1:06:40,  3.40s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 4be9a4a51bce6965\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  11%|\u001b[34m█         \u001b[0m| 142/1316 [05:20<56:54,  2.91s/it]  ","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 8c4c430c7d86612b\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  12%|\u001b[34m█▏        \u001b[0m| 158/1316 [05:54<44:21,  2.30s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 3a40c9bae0bcde82\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  13%|\u001b[34m█▎        \u001b[0m| 166/1316 [06:13<47:48,  2.49s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: b9ad6a4219c59a2f\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  13%|\u001b[34m█▎        \u001b[0m| 172/1316 [06:26<45:22,  2.38s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 2979a5efeeb8e2de\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  14%|\u001b[34m█▍        \u001b[0m| 189/1316 [07:06<45:02,  2.40s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 38a8a97dfaca1542\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  15%|\u001b[34m█▍        \u001b[0m| 197/1316 [07:24<44:32,  2.39s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 4df4e82b8282a26b\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  19%|\u001b[34m█▉        \u001b[0m| 253/1316 [09:34<42:06,  2.38s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 8f0d7fae086996f5\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  19%|\u001b[34m█▉        \u001b[0m| 254/1316 [09:37<44:55,  2.54s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 34e34c14edf5cf11\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  21%|\u001b[34m██        \u001b[0m| 270/1316 [10:14<42:20,  2.43s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 2e74005640f85b7b\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  25%|\u001b[34m██▍       \u001b[0m| 328/1316 [12:21<38:44,  2.35s/it]","output_type":"stream"}],"execution_count":null}]}