{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10715587,"sourceType":"datasetVersion","datasetId":6347856}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n    # for filename in filenames:\n    #     print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:49:58.843853Z","iopub.execute_input":"2025-02-11T06:49:58.844161Z","iopub.status.idle":"2025-02-11T06:49:59.163806Z","shell.execute_reply.started":"2025-02-11T06:49:58.844139Z","shell.execute_reply":"2025-02-11T06:49:59.162960Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip -q install --upgrade ollama","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:50:01.444762Z","iopub.execute_input":"2025-02-11T06:50:01.445192Z","iopub.status.idle":"2025-02-11T06:50:06.102102Z","shell.execute_reply.started":"2025-02-11T06:50:01.445165Z","shell.execute_reply":"2025-02-11T06:50:06.100865Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!curl -fsSL https://ollama.com/install.sh | sh","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:50:06.103731Z","iopub.execute_input":"2025-02-11T06:50:06.104083Z","iopub.status.idle":"2025-02-11T06:50:48.300973Z","shell.execute_reply.started":"2025-02-11T06:50:06.104049Z","shell.execute_reply":"2025-02-11T06:50:48.300172Z"}},"outputs":[{"name":"stdout","text":">>> Installing ollama to /usr/local\n>>> Downloading Linux amd64 bundle\n############################################################################################# 100.0%################                                                                         24.5%############################                                                      45.0%\n>>> Creating ollama user...\n>>> Adding ollama user to video group...\n>>> Adding current user to ollama group...\n>>> Creating ollama systemd service...\n\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n>>> The Ollama API is now available at 127.0.0.1:11434.\n>>> Install complete. Run \"ollama\" from the command line.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nget_ipython().system = os.system","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:50:48.302460Z","iopub.execute_input":"2025-02-11T06:50:48.302718Z","iopub.status.idle":"2025-02-11T06:50:48.306415Z","shell.execute_reply.started":"2025-02-11T06:50:48.302674Z","shell.execute_reply":"2025-02-11T06:50:48.305607Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!ollama serve &","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:50:48.307302Z","iopub.execute_input":"2025-02-11T06:50:48.307524Z","iopub.status.idle":"2025-02-11T06:50:48.325089Z","shell.execute_reply.started":"2025-02-11T06:50:48.307488Z","shell.execute_reply":"2025-02-11T06:50:48.324060Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"!ollama pull aya:8b","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:50:48.326057Z","iopub.execute_input":"2025-02-11T06:50:48.326341Z","iopub.status.idle":"2025-02-11T06:51:22.243584Z","shell.execute_reply.started":"2025-02-11T06:50:48.326311Z","shell.execute_reply":"2025-02-11T06:51:22.242813Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"!ollama show aya:8b","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:53:30.018282Z","iopub.execute_input":"2025-02-11T06:53:30.018651Z","iopub.status.idle":"2025-02-11T06:53:30.086915Z","shell.execute_reply.started":"2025-02-11T06:53:30.018623Z","shell.execute_reply":"2025-02-11T06:53:30.086116Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import json\nfrom tqdm import tqdm\nimport ollama\n\n# from langchain_community.chat_models import ChatOllama\n# from langchain.document_loaders import WikipediaLoader\n# # from langchain_community.llms import Ollama\n# from langchain_ollama import OllamaLLM\n# from langchain.chains import LLMChain\n# from langchain.prompts.chat import (ChatPromptTemplate,HumanMessagePromptTemplate,SystemMessagePromptTemplate)\n# from langchain import PromptTemplate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:53:37.832034Z","iopub.execute_input":"2025-02-11T06:53:37.832327Z","iopub.status.idle":"2025-02-11T06:53:37.836345Z","shell.execute_reply.started":"2025-02-11T06:53:37.832306Z","shell.execute_reply":"2025-02-11T06:53:37.835294Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Path to your input and output files\ninput_file = \"/kaggle/input/task-2-ea-mt-entity-aware-machine-translation/semeval.test_hidden/test_without_targets/ja_JP.jsonl\"\noutput_file = \"translated_data_en_ja_ollama-aya-8b-v3.jsonl\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:54:52.499597Z","iopub.execute_input":"2025-02-11T06:54:52.499946Z","iopub.status.idle":"2025-02-11T06:54:52.503827Z","shell.execute_reply.started":"2025-02-11T06:54:52.499919Z","shell.execute_reply":"2025-02-11T06:54:52.502919Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def translate_text(obj):\n    prompt = f\"\"\"\n    Translate the following English text into Japanese with a more attention on accurately translating the given name entities. \n    Do not add extra text.\n    \n    Entity Types: {', '.join(obj['entity_types'])}\n    Text: \"{obj['source']}\"\n    \n    Output the result in JSON format:\n    {{\n        \"id\": \"{obj['id']}\",\n        \"predicted_text\": \"<translated_text>\"\n    }}\n    \"\"\"\n    \n    response = ollama.chat(\n        model=\"aya:8b\",\n        messages=[{\"role\": \"system\", \"content\": \"You are a translation assistant.\"},\n                  {\"role\": \"user\", \"content\": prompt}],\n        stream=False\n    )\n    \n    # Extract generated text and parse JSON\n    try:\n        # print(response)\n        output_json = json.loads(response.message.content)\n        return output_json\n    except json.JSONDecodeError:\n        print(f\"Error parsing response for ID: {obj['id']}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:53:41.382142Z","iopub.execute_input":"2025-02-11T06:53:41.382431Z","iopub.status.idle":"2025-02-11T06:53:41.388086Z","shell.execute_reply.started":"2025-02-11T06:53:41.382408Z","shell.execute_reply":"2025-02-11T06:53:41.386814Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"with open(input_file, \"r\", encoding=\"utf-8\") as f:\n    total_lines = sum(1 for _ in f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:53:43.682623Z","iopub.execute_input":"2025-02-11T06:53:43.683012Z","iopub.status.idle":"2025-02-11T06:53:43.741101Z","shell.execute_reply.started":"2025-02-11T06:53:43.682984Z","shell.execute_reply":"2025-02-11T06:53:43.740319Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Read input file and translate each object\nwith open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n    with tqdm(total=total_lines, desc=\"Generating Predictions\", colour=\"blue\") as pbar:\n            for line in infile:\n                obj = json.loads(line.strip())\n                translated_obj = translate_text(obj)\n                # print(\"Before: \", translated_obj)\n                \n                # print(\"After: \", translated_obj)\n                # break\n                if translated_obj:\n                    translated_obj = {\n                    \"id\": translated_obj[\"id\"],\n                    \"source_language\": \"English\",\n                    \"target_language\": \"Japanese\", \n                    \"text\": obj[\"source\"],\n                    \"prediction\": translated_obj[\"predicted_text\"]\n                    \n                    }\n                    outfile.write(json.dumps(translated_obj, ensure_ascii=False) + \"\\n\")\n                pbar.update(1)\n\nprint(f\"Translation completed! Output saved to {output_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T06:54:59.454487Z","iopub.execute_input":"2025-02-11T06:54:59.454862Z"}},"outputs":[{"name":"stderr","text":"Generating Predictions:  14%|\u001b[34m█▎        \u001b[0m| 699/5108 [20:41<1:58:56,  1.62s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 1d88ccf22f52e004\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  15%|\u001b[34m█▌        \u001b[0m| 779/5108 [22:59<3:26:54,  2.87s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: d7e9d2fedb28009b\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  16%|\u001b[34m█▌        \u001b[0m| 812/5108 [24:08<3:47:01,  3.17s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: c6683d34039305fe\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  16%|\u001b[34m█▋        \u001b[0m| 837/5108 [24:49<1:54:14,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: ed3cb9dc834696e1\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  17%|\u001b[34m█▋        \u001b[0m| 858/5108 [25:27<2:28:36,  2.10s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 66f85ac0164ace03\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  19%|\u001b[34m█▉        \u001b[0m| 995/5108 [29:27<1:56:54,  1.71s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 24cb67125aaceea6\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  23%|\u001b[34m██▎       \u001b[0m| 1152/5108 [34:21<2:04:10,  1.88s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: e196358bc3bc567e\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  35%|\u001b[34m███▍      \u001b[0m| 1784/5108 [52:50<1:52:09,  2.02s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: a491225df867b9f1\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  35%|\u001b[34m███▍      \u001b[0m| 1785/5108 [52:52<1:50:35,  2.00s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 2808236b5a0eeecd\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  36%|\u001b[34m███▌      \u001b[0m| 1848/5108 [54:52<1:31:33,  1.69s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 70d80992edc9b8c2\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  37%|\u001b[34m███▋      \u001b[0m| 1897/5108 [56:29<2:06:21,  2.36s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: f996f28e4fbc6a81\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  37%|\u001b[34m███▋      \u001b[0m| 1899/5108 [56:33<2:03:01,  2.30s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 0debac9c3c8d2b4f\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  39%|\u001b[34m███▊      \u001b[0m| 1974/5108 [58:51<1:29:30,  1.71s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 89b61106ed883ffa\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  39%|\u001b[34m███▊      \u001b[0m| 1975/5108 [58:53<1:30:46,  1.74s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: f981daa0c96202c0\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  40%|\u001b[34m███▉      \u001b[0m| 2037/5108 [1:00:38<2:00:35,  2.36s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: a4ea212726f1bfc0\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  40%|\u001b[34m████      \u001b[0m| 2064/5108 [1:01:27<1:22:29,  1.63s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 244db0bfb2669710\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  51%|\u001b[34m█████     \u001b[0m| 2615/5108 [1:18:15<1:42:27,  2.47s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 06b7cfd839f55242\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  51%|\u001b[34m█████▏    \u001b[0m| 2627/5108 [1:18:34<1:07:25,  1.63s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 262fbd5833387923\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  52%|\u001b[34m█████▏    \u001b[0m| 2644/5108 [1:19:03<1:06:14,  1.61s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: ae7a933b7327dd61\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  52%|\u001b[34m█████▏    \u001b[0m| 2663/5108 [1:19:34<1:09:32,  1.71s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 23765b7e45226060\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  55%|\u001b[34m█████▌    \u001b[0m| 2820/5108 [1:24:23<1:05:27,  1.72s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 8a36fc222fc184ea\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  56%|\u001b[34m█████▋    \u001b[0m| 2877/5108 [1:26:05<1:00:30,  1.63s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 87893daf231e00ff\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  57%|\u001b[34m█████▋    \u001b[0m| 2897/5108 [1:26:39<1:05:51,  1.79s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 6c5dfa4a9ebc66bf\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  57%|\u001b[34m█████▋    \u001b[0m| 2900/5108 [1:26:44<1:01:32,  1.67s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 3ebd94b1fd90da49\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  57%|\u001b[34m█████▋    \u001b[0m| 2925/5108 [1:27:32<1:04:35,  1.78s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 28b1eff76c9f889f\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  60%|\u001b[34m██████    \u001b[0m| 3073/5108 [1:31:46<1:02:07,  1.83s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: f3ec1fb8f5ad8315\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  66%|\u001b[34m██████▌   \u001b[0m| 3372/5108 [1:40:57<1:10:44,  2.44s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 54ebcb426d4902c5\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  66%|\u001b[34m██████▋   \u001b[0m| 3391/5108 [1:41:29<54:22,  1.90s/it]  ","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: cc95314333441cde\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  69%|\u001b[34m██████▉   \u001b[0m| 3521/5108 [1:45:31<51:47,  1.96s/it]  ","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: a01e56e1f8dc1bb1\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  69%|\u001b[34m██████▉   \u001b[0m| 3547/5108 [1:46:14<46:16,  1.78s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 6901ba70572ed341\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  70%|\u001b[34m███████   \u001b[0m| 3579/5108 [1:47:10<1:04:28,  2.53s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: c117c94e721c69f6\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  70%|\u001b[34m███████   \u001b[0m| 3580/5108 [1:47:12<59:04,  2.32s/it]  ","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: e81d3cfbc44d7ad1\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  70%|\u001b[34m███████   \u001b[0m| 3584/5108 [1:47:22<1:07:29,  2.66s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 0e13935c811d8e9d\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  71%|\u001b[34m███████   \u001b[0m| 3619/5108 [1:48:30<1:02:55,  2.54s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 7629bdb841446d07\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  72%|\u001b[34m███████▏  \u001b[0m| 3703/5108 [1:51:02<43:15,  1.85s/it]  ","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 89bc317f089fabde\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  76%|\u001b[34m███████▋  \u001b[0m| 3901/5108 [1:57:12<43:58,  2.19s/it]  ","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 0030903e9d841b34\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  87%|\u001b[34m████████▋ \u001b[0m| 4466/5108 [2:13:46<17:52,  1.67s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 22f5a5019c1a5470\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  91%|\u001b[34m█████████ \u001b[0m| 4633/5108 [2:18:55<14:28,  1.83s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 55ccff5d895cd85f\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  91%|\u001b[34m█████████ \u001b[0m| 4658/5108 [2:19:38<12:34,  1.68s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 7be14d939f85622c\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  93%|\u001b[34m█████████▎\u001b[0m| 4740/5108 [2:22:06<10:55,  1.78s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 6e17cb6d97250f09\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions:  99%|\u001b[34m█████████▉\u001b[0m| 5047/5108 [2:31:19<01:41,  1.67s/it]","output_type":"stream"},{"name":"stdout","text":"Error parsing response for ID: 7c21105b9aaf1fe9\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions: 100%|\u001b[34m█████████▉\u001b[0m| 5090/5108 [2:32:38<00:31,  1.75s/it]","output_type":"stream"}],"execution_count":null}]}